{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import fr_core_news_sm\n",
    "from spacy_language_detection import LanguageDetector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import srsly\n",
    "\n",
    "from spacy.training import JsonlCorpus\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.matcher import Matcher, DependencyMatcher, PhraseMatcher\n",
    "from spacy.tokens import Token, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We're using a component factory because the component needs to be\n",
    "# initialized with the shared vocab via the nlp object\n",
    "@Language.factory(\"flag_loc\", default_config={'path_departure':'patterns_departure.jsonl',\n",
    "                                              \"path_destination\": 'patterns_destination.jsonl',\n",
    "                                             \"path_steps\": 'patterns_steps.jsonl'})\n",
    "def flag_destination(nlp, name, path_departure, path_steps, path_destination):\n",
    "    return LocMatcher(nlp.vocab, path_departure, path_steps, path_destination)\n",
    "\n",
    "@Language.factory(\"language_detector\")\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "Token.set_extension('loc', default=None, force=True)\n",
    "\n",
    "class LocMatcher:\n",
    "    def __init__(self, vocab, path_departure, path_steps, path_destination): \n",
    "        self.matcher = Matcher(vocab)\n",
    "        self.patterns_departure = [[pattern for pattern in srsly.read_jsonl(path_departure)]]\n",
    "        self.patterns_steps = [[pattern for pattern in srsly.read_jsonl(path_steps)]]\n",
    "        self.patterns_destination = [[pattern for pattern in srsly.read_jsonl(path_destination)]]\n",
    "        self.matcher.add('DEPARTURE', self.patterns_departure)\n",
    "        self.matcher.add('STEPS', self.patterns_steps)\n",
    "        self.matcher.add('DESTINATION', self.patterns_destination)\n",
    "    def __call__(self, doc):\n",
    "        # This method is invoked when the component is called on a Doc\n",
    "        new_ents = []  # Collect the matched spans here\n",
    "        for idx, ent in enumerate(doc.ents):\n",
    "            previous_span = doc[ent.start-2: ent.start]\n",
    "            match = self.matcher(previous_span)\n",
    "            if match: # ensure that there are more than first term 'à' or 'de'\n",
    "                new_ents.append(Span(doc, ent.start, ent.end, label=match[0][0]))\n",
    "            else:\n",
    "                new_ents.append(ent)\n",
    "        doc.ents = new_ents\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "nlp.add_pipe(\"flag_loc\", last=True)  # Add component to the pipeline\n",
    "phrase = 'en partant de gare de lyon je souhaite me rendre à lyon perache'\n",
    "phrase1 = \"j'aimerais partir de Paris et passer par biarritz pour me rendre à Marseille\"\n",
    "phrase2 = \"Je suis à Charenton-Le-Pont et je souhaite me rendre à Vélizy\"\n",
    "doc = nlp(phrase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de Flake8\n",
    "# Programme qui capture un enregistrement via le microphone/fichier audio\n",
    "# Et qui traitera les données enregistré\n",
    "\n",
    "# Fonction de capture de son par le microphone\n",
    "# Check si la capture est en francais ou pas\n",
    "# Si oui retourne le contenu de la capture\n",
    "# Si non vous demande de recommencer l'enregistrement\n",
    "\n",
    "\n",
    "def capture_mic(microphone):\n",
    "    r = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=microphone)\n",
    "\n",
    "    with mic as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"you can start to talk\")\n",
    "        audio = r.listen(source)\n",
    "    text_data = r.recognize_google(audio, language=\"fr-FR\")\n",
    "\n",
    "    doc = nlp(text_data)\n",
    "    detected = doc._.language\n",
    "    print(detected)\n",
    "    if detected['language'] == \"fr\":\n",
    "        print(\"c'est bien du francais\")\n",
    "        print(text_data)\n",
    "        return text_data\n",
    "    else:\n",
    "        print(\"ce n'est pas du francais veuillez recommencer\")\n",
    "        capture_mic(1)\n",
    "\n",
    "\n",
    "text_to_process = capture_mic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# assume you have a \"long-form\" data frame\n",
    "# see https://plotly.com/python/px-arguments/ for more options\n",
    "df = pd.DataFrame({\n",
    "    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n",
    "    \"Amount\": [4, 1, 2, 2, 4, 5],\n",
    "    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n",
    "})\n",
    "\n",
    "fig = px.bar(df, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for your data.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure=fig\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
