title: 'add destination, steps and departure to localtion entity)'
description: " Project AI"
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "localizer"
  config: "localizer.cfg"
  vectors_model: "fr_core_news_md"
  patterns_destination: "patterns_destination.jsonl"
  patterns_departure: "patterns_departure.jsonl"
  patterns_steps: "patterns_steps.jsonl"
  annotations: "data.csv"
  nlp_regex: "nlp_regex"
  nlp_xgb: "nlp_xgb"
  train: "train"
  dev: "dev"
  version: "0.0.1"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "configs", "scripts"]

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - setup
    - download
    - corpus
    - assemble
    - assemble_xgb
    - evaluate_regex
    - evaluate_xgb

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: download
    help: "Download a spaCy model with pretrained vectors"
    script:
      - "python -m spacy download ${vars.vectors_model}"

  - name: assemble
    help: "Build one version of the pipeline."
    script:
      - "python ./scripts/create_matcher_model.py ./assets/${vars.patterns_destination} ./assets/${vars.patterns_departure} ./assets/${vars.patterns_steps} ${vars.vectors_model} temp/${vars.nlp_regex}"
    outputs_no_cache:
      - "temp/${vars.nlp_regex}"
      - "scripts/create_matcher_model.py"
      
  - name: assemble_xgb
    help: "Build one version of the pipeline."
    script:
      - "python ./scripts/create_xgboost_model.py corpus/${vars.train}.spacy ${vars.vectors_model} temp/${vars.nlp_xgb}"
    outputs_no_cache:
      - "temp/${vars.nlp_xgb}"
      - "scripts/create_xgboost_model.py"

  - name: corpus
    help: "Create a training and dev set from the manually annotated data"
    script:
      - "python ./scripts/create_corpus.py 0.8 ./assets/${vars.annotations} ./temp/${vars.nlp_regex}/ corpus/${vars.train}.spacy corpus/${vars.dev}.spacy"
    deps:
      - "assets/${vars.annotations}"
    outputs_no_cache:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"
      
  - name: evaluate_regex
    help: "Evaluate the model and export metrics"
    script:
      - "python -m spacy evaluate temp/${vars.nlp_regex}/ corpus/${vars.dev}.spacy --output metrics_regex.json --code  ./scripts/create_matcher_model.py"
    deps:
      - "corpus/${vars.dev}.spacy"
    outputs:
      - "metrics_regex.json"

  - name: evaluate_xgb
    help: "Evaluate the model and export metrics"
    script:
      - "python -m spacy evaluate temp/${vars.nlp_xgb}/ corpus/${vars.dev}.spacy --output metrics_xgb.json --code  ./scripts/create_xgboost_model.py"
    deps:
      - "corpus/${vars.dev}.spacy"
    outputs:
      - "metrics_xgb.json"
      
  - name: setup
    help: Install dependencies
    script:
      - "python -m pip install -r requirements.txt"
    deps:
      - "requirements.txt"